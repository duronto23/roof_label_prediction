{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590d8eba",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "\n",
    "Given two sets of satellite images: the first set includes corresponding labels that identify roof areas, while the second set consists of unlabeled images. \n",
    "\n",
    "The objective is to train an appropriate neural network model using the first set of images and their labels, and then use the trained model to predict labels for the second set of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3dd8b7",
   "metadata": {},
   "source": [
    "## Approach\n",
    "Utilize the provided training data to train multiple neural network models, compare their accuracy, and select the best-performing model for predicting labels on the given second set of images. The models to be tested include **DeepLabv3** (with various backbone/base models) and **U-Net**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11436a",
   "metadata": {},
   "source": [
    "### Step 1: Importing Libreries\n",
    "Import the necessary libraries required for the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67b38d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6650b5",
   "metadata": {},
   "source": [
    "### Step 2: Data Loading and Processing\n",
    "Given first set of images and labels are stored in the following locations:\n",
    "**Images** : `dataset/train/images`\n",
    "**Labels** : `dataset/train/labels`\n",
    "\n",
    "In this step, will read images with OpenCV libreary and labels and afterwards resize normalize them.\n",
    "Finally, load them as numpy array.\n",
    "* Dercribes every steps in comments in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1321afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir, label_dir, img_size=(256, 256)):\n",
    "    images, labels = [], []\n",
    "    for file_name in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, file_name)\n",
    "        label_path = os.path.join(label_dir, file_name)\n",
    "        \n",
    "        if img_path.endswith(\"png\") and label_path.endswith(\"png\"):\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0\n",
    "\n",
    "            lbl = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "            lbl = cv2.resize(lbl, img_size)\n",
    "            lbl = lbl / 255.0\n",
    "            lbl = np.expand_dims(lbl, axis=-1)\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(lbl)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_data(\"dataset/train/images\", \"dataset/train/labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af354c6d",
   "metadata": {},
   "source": [
    "### Step 3: Splitting the Data into Train and Validation Sets\n",
    "The data has been split into training and validation sets. The configuration ensures that 90% of the data is used for training and 10% for testing. A random state of 42 is used to maintain consistency between separate runs.\n",
    "_N.B: Usually 80% and 20% represent a standard spliting, but as the availabale amount of data is very limited, so using 90% of data to train the model to get better accuracy._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e167377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b501529",
   "metadata": {},
   "source": [
    "### Step 4: Selection of Model and Hyperparameter Tuning\n",
    "In this process, I will explore multiple neural network models, including **DeepLabv3** and **U-Net**. After evaluating their performance, I will select the best-performing models to predict labels for the second set of images. \n",
    "\n",
    "For **DeepLabv3**, I will experiment with different base models and choose the one with the highest accuracy among them. **U-Net**, with its distinct architecture, is effective at capturing edges and boundaries in labels, where DeepLabv3 may not perform as well. Therefore, I will also use U-Net for predictions.\n",
    "\n",
    "Additionally, I will perform parameter tuning to optimize each model for the best possible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd31e37",
   "metadata": {},
   "source": [
    "#### Define and train DeepLabv3 model\n",
    "Following blcok is a function to create DeepLabv3 Model with privided backbone or base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88808839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deeplabv3_model(base_model, num_classes=1):\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b38b75",
   "metadata": {},
   "source": [
    "#### Functions to tune params and train DeepLabv3 model\n",
    "The following block defines functions to tune hyperparameters and train the DeepLabv3 model with the provided backbone or base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db15e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(base_model_param):\n",
    "    if base_model_param == 'xception':\n",
    "        return tf.keras.applications.Xception(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    if base_model_param == 'resnet50':\n",
    "        return tf.keras.applications.ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    if base_model_param == 'resnet101':\n",
    "        return tf.keras.applications.ResNet101(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    if base_model_param == 'mobilenetv2':\n",
    "        return tf.keras.applications.MobileNetV2(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    return None\n",
    "\n",
    "\n",
    "def tune_and_train():\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.001, 0.0001],\n",
    "        'batch_size': [8, 16],\n",
    "        'optimizer': ['adam', 'sgd'],\n",
    "        'epochs': [50, 75, 100],\n",
    "        'base_model': ['xception', 'resnet50', 'resnet101', 'mobilenetv2']\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"Testing parameters: {params}\")\n",
    "\n",
    "        base_model = get_base_model(params['base_model'])\n",
    "        if base_model == None:\n",
    "            continue\n",
    "            \n",
    "        model = get_deeplabv3_model(base_model)\n",
    "\n",
    "        if params['optimizer'] == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "        elif params['optimizer'] == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=params['learning_rate'], momentum=0.9)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_loss = history.history['val_loss'][-1]\n",
    "        print(f\"Validation loss: {val_loss}\")\n",
    "\n",
    "        if val_loss < best_score:\n",
    "            best_score = val_loss\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best Validation Loss: {best_score}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553b45e",
   "metadata": {},
   "source": [
    "#### Deine and train DeepLabv3 model\n",
    "In following step, I will tune and train DeepLabv3 model and will pick the better performer DeepLabv3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ec21a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'base_model': 'xception', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 9s 2s/step - loss: 0.8754 - accuracy: 0.4857 - val_loss: 0.6800 - val_accuracy: 0.8724\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7038 - accuracy: 0.5291 - val_loss: 0.6656 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6656394600868225\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.8667 - accuracy: 0.4790 - val_loss: 0.6911 - val_accuracy: 0.8721\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8592 - accuracy: 0.4822 - val_loss: 0.6866 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6866357922554016\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.8657 - accuracy: 0.4822 - val_loss: 0.6922 - val_accuracy: 0.8097\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7966 - accuracy: 0.5020 - val_loss: 0.6912 - val_accuracy: 0.8464\n",
      "Validation loss: 0.6911733746528625\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.9179 - accuracy: 0.4799 - val_loss: 0.6929 - val_accuracy: 0.6537\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9149 - accuracy: 0.4808 - val_loss: 0.6924 - val_accuracy: 0.7966\n",
      "Validation loss: 0.6923906207084656\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.8733 - accuracy: 0.4843 - val_loss: 0.6865 - val_accuracy: 0.8724\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.7379 - accuracy: 0.5078 - val_loss: 0.6782 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6781835556030273\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.8577 - accuracy: 0.4824 - val_loss: 0.6921 - val_accuracy: 0.8655\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.8605 - accuracy: 0.4812 - val_loss: 0.6898 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6898117661476135\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.9051 - accuracy: 0.4824 - val_loss: 0.6925 - val_accuracy: 0.7866\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.8281 - accuracy: 0.4982 - val_loss: 0.6920 - val_accuracy: 0.8349\n",
      "Validation loss: 0.6919517517089844\n",
      "Testing parameters: {'base_model': 'xception', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.8618 - accuracy: 0.4779 - val_loss: 0.6931 - val_accuracy: 0.5515\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.8653 - accuracy: 0.4767 - val_loss: 0.6929 - val_accuracy: 0.7069\n",
      "Validation loss: 0.6928500533103943\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.8286 - accuracy: 0.4910 - val_loss: 0.6826 - val_accuracy: 0.8714\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6550 - accuracy: 0.6617 - val_loss: 0.6812 - val_accuracy: 0.8613\n",
      "Validation loss: 0.6812118887901306\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.8905 - accuracy: 0.4777 - val_loss: 0.6907 - val_accuracy: 0.8667\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.8872 - accuracy: 0.4805 - val_loss: 0.6858 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6858078837394714\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.8728 - accuracy: 0.4767 - val_loss: 0.6922 - val_accuracy: 0.7660\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7801 - accuracy: 0.5088 - val_loss: 0.6912 - val_accuracy: 0.8352\n",
      "Validation loss: 0.6912451386451721\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 8s 2s/step - loss: 0.8755 - accuracy: 0.4785 - val_loss: 0.6929 - val_accuracy: 0.5833\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8745 - accuracy: 0.4785 - val_loss: 0.6924 - val_accuracy: 0.7482\n",
      "Validation loss: 0.6923980116844177\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.8660 - accuracy: 0.4854 - val_loss: 0.6931 - val_accuracy: 0.6241\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.6781 - accuracy: 0.6217 - val_loss: 0.6944 - val_accuracy: 0.5750\n",
      "Validation loss: 0.6944448947906494\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.8861 - accuracy: 0.4790 - val_loss: 0.6921 - val_accuracy: 0.7584\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.8825 - accuracy: 0.4805 - val_loss: 0.6896 - val_accuracy: 0.8666\n",
      "Validation loss: 0.6896295547485352\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.8606 - accuracy: 0.4791 - val_loss: 0.6927 - val_accuracy: 0.6900\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.7710 - accuracy: 0.5117 - val_loss: 0.6922 - val_accuracy: 0.7563\n",
      "Validation loss: 0.6922318339347839\n",
      "Testing parameters: {'base_model': 'resnet50', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.8392 - accuracy: 0.4792 - val_loss: 0.6932 - val_accuracy: 0.5118\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.8390 - accuracy: 0.4773 - val_loss: 0.6929 - val_accuracy: 0.5791\n",
      "Validation loss: 0.6929430365562439\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 15s 3s/step - loss: 0.7789 - accuracy: 0.5352 - val_loss: 0.6846 - val_accuracy: 0.8691\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.5833 - accuracy: 0.7538 - val_loss: 0.6866 - val_accuracy: 0.7056\n",
      "Validation loss: 0.6865587830543518\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 14s 3s/step - loss: 0.9035 - accuracy: 0.4780 - val_loss: 0.6905 - val_accuracy: 0.8628\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.8980 - accuracy: 0.4812 - val_loss: 0.6849 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6848971247673035\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 14s 3s/step - loss: 0.8760 - accuracy: 0.4792 - val_loss: 0.6923 - val_accuracy: 0.7682\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.7878 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.8436\n",
      "Validation loss: 0.6912733912467957\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3/3 [==============================] - 14s 3s/step - loss: 0.8742 - accuracy: 0.4793 - val_loss: 0.6929 - val_accuracy: 0.5982\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.8769 - accuracy: 0.4792 - val_loss: 0.6925 - val_accuracy: 0.7467\n",
      "Validation loss: 0.6924509406089783\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 15s 4s/step - loss: 0.8699 - accuracy: 0.4814 - val_loss: 0.6861 - val_accuracy: 0.7699\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.6935 - accuracy: 0.5785 - val_loss: 0.6801 - val_accuracy: 0.8656\n",
      "Validation loss: 0.68012934923172\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 3s/step - loss: 0.9033 - accuracy: 0.4783 - val_loss: 0.6920 - val_accuracy: 0.7820\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.9026 - accuracy: 0.4807 - val_loss: 0.6892 - val_accuracy: 0.8722\n",
      "Validation loss: 0.6892430186271667\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 15s 3s/step - loss: 0.8472 - accuracy: 0.4837 - val_loss: 0.6926 - val_accuracy: 0.7320\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 8s 3s/step - loss: 0.7780 - accuracy: 0.5096 - val_loss: 0.6920 - val_accuracy: 0.8185\n",
      "Validation loss: 0.692035973072052\n",
      "Testing parameters: {'base_model': 'resnet101', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 3s/step - loss: 0.8854 - accuracy: 0.4817 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.8873 - accuracy: 0.4790 - val_loss: 0.6927 - val_accuracy: 0.6239\n",
      "Validation loss: 0.6927410960197449\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 4s 706ms/step - loss: 0.8220 - accuracy: 0.4996 - val_loss: 0.6816 - val_accuracy: 0.8724\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 1s 435ms/step - loss: 0.6897 - accuracy: 0.5479 - val_loss: 0.6702 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6701536774635315\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 671ms/step - loss: 0.8984 - accuracy: 0.4753 - val_loss: 0.6905 - val_accuracy: 0.8456\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 1s 418ms/step - loss: 0.8946 - accuracy: 0.4767 - val_loss: 0.6850 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6849803924560547\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 4s 663ms/step - loss: 0.8987 - accuracy: 0.4791 - val_loss: 0.6922 - val_accuracy: 0.7206\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 0.8276 - accuracy: 0.4957 - val_loss: 0.6911 - val_accuracy: 0.8190\n",
      "Validation loss: 0.6910967826843262\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 4s 666ms/step - loss: 0.8806 - accuracy: 0.4735 - val_loss: 0.6926 - val_accuracy: 0.5969\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 1s 421ms/step - loss: 0.8796 - accuracy: 0.4740 - val_loss: 0.6922 - val_accuracy: 0.7022\n",
      "Validation loss: 0.6922033429145813\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 5s 906ms/step - loss: 0.8621 - accuracy: 0.4909 - val_loss: 0.6869 - val_accuracy: 0.8703\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.7000 - accuracy: 0.5660 - val_loss: 0.6794 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6794166564941406\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 4s 963ms/step - loss: 0.9020 - accuracy: 0.4789 - val_loss: 0.6918 - val_accuracy: 0.7580\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 0.9001 - accuracy: 0.4795 - val_loss: 0.6893 - val_accuracy: 0.8640\n",
      "Validation loss: 0.6892535090446472\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 4s 901ms/step - loss: 0.8614 - accuracy: 0.4810 - val_loss: 0.6926 - val_accuracy: 0.6837\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.8158 - accuracy: 0.4934 - val_loss: 0.6921 - val_accuracy: 0.7770\n",
      "Validation loss: 0.6921076774597168\n",
      "Testing parameters: {'base_model': 'mobilenetv2', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 4s 891ms/step - loss: 0.8667 - accuracy: 0.4789 - val_loss: 0.6931 - val_accuracy: 0.5043\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.8645 - accuracy: 0.4815 - val_loss: 0.6929 - val_accuracy: 0.5714\n",
      "Validation loss: 0.6928719878196716\n",
      "Best Parameters: {'base_model': 'xception', 'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Best Validation Loss: 0.6656394600868225\n"
     ]
    }
   ],
   "source": [
    "deeplabv3_model = tune_and_train()\n",
    "\n",
    "if deeplabv3_model:\n",
    "    deeplabv3_model.save(\"trained_deeplabv3_roof_segmentation.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d93a4",
   "metadata": {},
   "source": [
    "#### Define and train U-Net model with hyperparameter tuning\n",
    "In this step I will define a U-Net model with best fitting hyperparameter by tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c03de6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.6541 - accuracy: 0.7487 - val_loss: 0.4126 - val_accuracy: 0.8724\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.5026 - accuracy: 0.8286 - val_loss: 0.3852 - val_accuracy: 0.8724\n",
      "Validation loss: 0.38521531224250793\n",
      "Testing parameters: {'batch_size': 8, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.6876 - accuracy: 0.8053 - val_loss: 0.6832 - val_accuracy: 0.8603\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.6858 - accuracy: 0.8219 - val_loss: 0.6795 - val_accuracy: 0.8686\n",
      "Validation loss: 0.6795486807823181\n",
      "Testing parameters: {'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.6871 - accuracy: 0.7469 - val_loss: 0.6679 - val_accuracy: 0.8724\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.6714 - accuracy: 0.8285 - val_loss: 0.6425 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6424593329429626\n",
      "Testing parameters: {'batch_size': 8, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.6908 - accuracy: 0.7579 - val_loss: 0.6891 - val_accuracy: 0.8132\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.6905 - accuracy: 0.7742 - val_loss: 0.6886 - val_accuracy: 0.8273\n",
      "Validation loss: 0.688640832901001\n",
      "Testing parameters: {'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 15s 5s/step - loss: 0.6965 - accuracy: 0.3304 - val_loss: 0.5295 - val_accuracy: 0.8724\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 14s 4s/step - loss: 0.5882 - accuracy: 0.8286 - val_loss: 0.4240 - val_accuracy: 0.8724\n",
      "Validation loss: 0.42403659224510193\n",
      "Testing parameters: {'batch_size': 16, 'epochs': 2, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 4s/step - loss: 0.6898 - accuracy: 0.7778 - val_loss: 0.6867 - val_accuracy: 0.8467\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 14s 4s/step - loss: 0.6886 - accuracy: 0.8091 - val_loss: 0.6841 - val_accuracy: 0.8645\n",
      "Validation loss: 0.6840887069702148\n",
      "Testing parameters: {'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 4s/step - loss: 0.6858 - accuracy: 0.8133 - val_loss: 0.6699 - val_accuracy: 0.8704\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 14s 4s/step - loss: 0.6771 - accuracy: 0.8277 - val_loss: 0.6568 - val_accuracy: 0.8724\n",
      "Validation loss: 0.6567705273628235\n",
      "Testing parameters: {'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 4s/step - loss: 0.6877 - accuracy: 0.8099 - val_loss: 0.6844 - val_accuracy: 0.8562\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 13s 4s/step - loss: 0.6876 - accuracy: 0.8145 - val_loss: 0.6841 - val_accuracy: 0.8593\n",
      "Validation loss: 0.6841241717338562\n",
      "Best Parameters: {'batch_size': 8, 'epochs': 10, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "Best Validation Loss: 0.2838459312915802\n"
     ]
    }
   ],
   "source": [
    "def get_unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u1 = layers.concatenate([u1, c2])\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u2 = layers.concatenate([u2, c1])\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'batch_size': [8, 16],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'epochs': [50, 75, 100]\n",
    "}\n",
    "\n",
    "unet_model = None\n",
    "unet_score = float('inf')\n",
    "unet_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "    \n",
    "    model = get_unet_model()\n",
    "\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=params['learning_rate'], momentum=0.9)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "        \n",
    "    if val_loss < unet_score:\n",
    "        unet_score = val_loss\n",
    "        unet_model = model\n",
    "        unet_params = params\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Validation Loss: {best_score}\")\n",
    "\n",
    "if unet_model:\n",
    "    unet_model.save(\"trained_unet_roof_segmentation_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9deb4a5",
   "metadata": {},
   "source": [
    "### Step 5: Predict labels for given images\n",
    "In this steo, will predict the labels for second set of images with better performer model of DeepLabV3 and U-Net model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f3330",
   "metadata": {},
   "source": [
    "#### Helper function to predict and save new labels using any given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c1cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(model, image_path, save_path, img_size=(256, 256)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, img_size) / 255.0\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_resized)[0]\n",
    "    prediction = (prediction > 0.5).astype(np.uint8)\n",
    "    \n",
    "    cv2.imwrite(save_path, prediction * 255)\n",
    "\n",
    "def predict_for_folder(model, images_dir, labels_dir):\n",
    "    for p in os.listdir(images_dir):\n",
    "        if p.endswith(\"png\"):\n",
    "            img_path = images_dir + '//' + p\n",
    "            lbl_path = labels_dir + '//' + p\n",
    "            print(\"Saving label for \"+img_path+\" to \"+lbl_path)\n",
    "            predict_and_save(model, img_path, lbl_path)\n",
    "            print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15a059",
   "metadata": {},
   "source": [
    "#### Following block is to predict and save labels for second set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e63088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving label for dataset/new_images//539.png to dataset/prediction/deeplabv3//539.png\n",
      "1/1 [==============================] - 1s 722ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//537.png to dataset/prediction/deeplabv3//537.png\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//535.png to dataset/prediction/deeplabv3//535.png\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//553.png to dataset/prediction/deeplabv3//553.png\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//551.png to dataset/prediction/deeplabv3//551.png\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//539.png to dataset/prediction/unet//539.png\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//537.png to dataset/prediction/unet//537.png\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//535.png to dataset/prediction/unet//535.png\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//553.png to dataset/prediction/unet//553.png\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "Done\n",
      "\n",
      "Saving label for dataset/new_images//551.png to dataset/prediction/unet//551.png\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_for_folder(deeplabv3_model, \"dataset/new_images\", \"dataset/prediction/deeplabv3\")\n",
    "\n",
    "predict_for_folder(unet_model, \"dataset/new_images\", \"dataset/prediction/unet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
