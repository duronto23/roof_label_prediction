{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590d8eba",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "\n",
    "Given two sets of satellite images: the first set includes corresponding labels that identify roof areas, while the second set consists of unlabeled images. \n",
    "\n",
    "The objective is to train an appropriate neural network model using the first set of images and their labels, and then use the trained model to predict labels for the second set of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3dd8b7",
   "metadata": {},
   "source": [
    "## Approach\n",
    "Utilize the provided training data to train multiple neural network models, compare their accuracy, and select the best-performing model for predicting labels on the given second set of images. The models to be tested include **DeepLabv3** (with various backbone/base models) and **U-Net**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11436a",
   "metadata": {},
   "source": [
    "### Step 1: Importing Libreries\n",
    "Import the necessary libraries required for the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b38d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6650b5",
   "metadata": {},
   "source": [
    "### Step 2: Data Loading and Processing\n",
    "Given first set of images and labels are stored in the following locations:\n",
    "**Images** : `dataset/train/images`\n",
    "**Labels** : `dataset/train/labels`\n",
    "\n",
    "In this step, will read images with OpenCV libreary and labels and afterwards resize normalize them.\n",
    "Finally, load them as numpy array.\n",
    "* Dercribes every steps in comments in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir, label_dir, img_size=(256, 256)):\n",
    "    images, labels = [], []\n",
    "    for file_name in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, file_name)\n",
    "        label_path = os.path.join(label_dir, file_name)\n",
    "        \n",
    "        if img_path.endswith(\"png\") and label_path.endswith(\"png\"):\n",
    "\n",
    "            img = cv2.imread(img_path) # Read Image\n",
    "            img = cv2.resize(img, img_size) # Resize Image\n",
    "            img = img / 255.0 # Normalizing\n",
    "\n",
    "            lbl = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)# Read Label(as Grayscale)\n",
    "            lbl = cv2.resize(lbl, img_size)\n",
    "            lbl = lbl / 255.0 # Normalize label (binary labels)\n",
    "            lbl = np.expand_dims(lbl, axis=-1) # Adding channel dimension\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(lbl)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function call to load data as numpy array\n",
    "images, labels = load_data(\"dataset/train/images\", \"dataset/train/labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af354c6d",
   "metadata": {},
   "source": [
    "### Step 3: Splitting the Data into Train and Validation Sets\n",
    "The data has been split into training and validation sets. The configuration ensures that 90% of the data is used for training and 10% for testing. A random state of 42 is used to maintain consistency between separate runs.\n",
    "_N.B: Usually 80% and 20% represent a standard spliting, but as the availabale amount of data is very limited, so using 90% of data to train the model to get better accuracy._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b501529",
   "metadata": {},
   "source": [
    "### Step 4: Selection of Model and Hyperparameter Tuning\n",
    "In this process, I will explore multiple neural network models, including **DeepLabv3** and **U-Net**. After evaluating their performance, I will select the best-performing models to predict labels for the second set of images. \n",
    "\n",
    "For **DeepLabv3**, I will experiment with different base models and choose the one with the highest accuracy among them. **U-Net**, with its distinct architecture, is effective at capturing edges and boundaries in labels, where DeepLabv3 may not perform as well. Therefore, I will also use U-Net for predictions.\n",
    "\n",
    "Additionally, I will perform parameter tuning to optimize each model for the best possible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd31e37",
   "metadata": {},
   "source": [
    "#### Define and train DeepLabv3 model\n",
    "Following blcok is a function to create DeepLabv3 Model with privided backbone or base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88808839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deeplabv3_model(base_model, num_classes=1):\n",
    "    \n",
    "    # Atrous Spatial Pyramid Pooling \n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Final layer to match label size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "    \n",
    "    # Ensuring output is (256, 256, num_classes)\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b38b75",
   "metadata": {},
   "source": [
    "#### Functions to tune params and train DeepLabv3 model\n",
    "The following block defines functions to tune hyperparameters and train the DeepLabv3 model with the provided backbone or base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get base model for hyperparameter value\n",
    "def get_base_model(base_model_param):\n",
    "    if base_model_param == 'xception':\n",
    "        return tf.keras.applications.Xception(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    if base_model_param == 'resnet50':\n",
    "        return tf.keras.applications.ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    if base_model_param == 'resnet101':\n",
    "        return tf.keras.applications.ResNet101(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    if base_model_param == 'mobilenetv2':\n",
    "        return tf.keras.applications.MobileNetV2(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3)\n",
    "        )\n",
    "    return None\n",
    "\n",
    "\n",
    "def tune_and_train():\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.001, 0.0001],\n",
    "        'batch_size': [8, 16],\n",
    "        'optimizer': ['adam', 'sgd'],\n",
    "        'epochs': [50, 75, 100],\n",
    "        'base_model': ['xception', 'resnet50', 'resnet101', 'mobilenetv2']\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"Testing parameters: {params}\")\n",
    "\n",
    "        base_model = get_base_model(params['base_model'])\n",
    "        if base_model == None: # Safe check\n",
    "            continue\n",
    "            \n",
    "        # Rebuild the model for each hyperparameter configuration\n",
    "        model = get_deeplabv3_model(base_model)\n",
    "\n",
    "        # Configuring optimizer\n",
    "        if params['optimizer'] == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "        elif params['optimizer'] == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=params['learning_rate'], momentum=0.9)\n",
    "\n",
    "        # Compilig the model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        # Training the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate performance on the validation set\n",
    "        val_loss = history.history['val_loss'][-1]\n",
    "        print(f\"Validation loss: {val_loss}\")\n",
    "\n",
    "        # Saving the best model configuration\n",
    "        if val_loss < best_score:\n",
    "            best_score = val_loss\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    # Print the best configuration\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best Validation Loss: {best_score}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553b45e",
   "metadata": {},
   "source": [
    "#### Deine and train DeepLabv3 model\n",
    "In following step, I will tune and train DeepLabv3 model and will pick the better performer DeepLabv3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec21a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling functiong get DeepLabV3 model with best hyperparamater\n",
    "deeplabv3_model = tune_and_train()\n",
    "\n",
    "# Saving the best model\n",
    "if deeplabv3_model:\n",
    "    deeplabv3_model.save(\"trained_deeplabv3_roof_segmentation.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d93a4",
   "metadata": {},
   "source": [
    "#### Define and train U-Net model with hyperparameter tuning\n",
    "In this step I will define a U-Net model with best fitting hyperparameter by tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03de6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u1 = layers.concatenate([u1, c2])\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u2 = layers.concatenate([u2, c1])\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'batch_size': [8, 16],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'epochs': [50, 75, 100]\n",
    "}\n",
    "\n",
    "unet_model = None\n",
    "unet_score = float('inf')\n",
    "unet_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "    \n",
    "    # Rebuild the U-Net model for each hyperparameter configuration\n",
    "    model = get_unet_model()\n",
    "\n",
    "    # Configuring optimizer\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=params['learning_rate'], momentum=0.9)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate performance on the validation set\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    \n",
    "    # Saving the best model configuration\n",
    "    if val_loss < unet_score:\n",
    "        unet_score = val_loss\n",
    "        unet_model = model\n",
    "        unet_params = params\n",
    "\n",
    "# Print the best configuration\n",
    "print(f\"Best Parameters: {unet_params}\")\n",
    "print(f\"Best Validation Loss: {unet_score}\")\n",
    "\n",
    "# Saving the best model\n",
    "if unet_model:\n",
    "    unet_model.save(\"trained_unet_roof_segmentation_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2838617f",
   "metadata": {},
   "source": [
    "### Resulting better performing hyperparameters after running a hyperparamater tuning \n",
    "\n",
    "During hyperparameter tuning and training , **DeepLabV3** was performend better with the better performing hyperparameter set as follows.\n",
    "```\n",
    "{\n",
    "    'base_model': 'xception',\n",
    "    'batch_size': 16,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 0.001,\n",
    "    'optimizer': 'adam'\n",
    "}\n",
    "```\n",
    "With a validation loss of `0.15872398018836975`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9deb4a5",
   "metadata": {},
   "source": [
    "### Step 5: Predict labels for given images\n",
    "In this step, will predict the labels for second set of images with better performer **DeepLabV3** model. I also included **U-Net** in prediction for reference.<br>_However, U-Net should ideally not be used for prediction as it was showing less accuracy during validation but I have included it only for reference._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f3330",
   "metadata": {},
   "source": [
    "#### Helper function to predict and save new labels using any given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(model, image_path, save_path, img_size=(256, 256)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, img_size) / 255.0\n",
    "    img_resized = np.expand_dims(img_resized, axis=0) # Add batch dimension\n",
    "    \n",
    "    prediction = model.predict(img_resized)[0]\n",
    "    prediction = (prediction > 0.5).astype(np.uint8) # Thresholding\n",
    "    \n",
    "    # Saving prediction as .png\n",
    "    cv2.imwrite(save_path, prediction * 255)\n",
    "\n",
    "def predict_for_folder(model, images_dir, labels_dir):\n",
    "    for p in os.listdir(images_dir):\n",
    "        if p.endswith(\"png\"):\n",
    "            img_path = images_dir + '//' + p\n",
    "            lbl_path = labels_dir + '//' + p\n",
    "            print(\"Saving label for \"+img_path+\" to \"+lbl_path)\n",
    "            predict_and_save(model, img_path, lbl_path)\n",
    "            print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15a059",
   "metadata": {},
   "source": [
    "#### Following block is to predict and save labels for second set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_folder(deeplabv3_model, \"dataset/new_images\", \"dataset/prediction/deeplabv3\")\n",
    "predict_for_folder(unet_model, \"dataset/new_images\", \"dataset/prediction/unet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
